import streamlit as st
import pandas as pd
import json
from datetime import datetime
import io
from ner_processor import ArabicNERProcessor

# Configure page
st.set_page_config(
    page_title="Arabic NER Extractor",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for RTL support and better Arabic text display
st.markdown("""
    <style>
    .arabic-text {
        direction: rtl;
        text-align: right;
        font-family: 'Traditional Arabic', 'Arial Unicode MS', sans-serif;
        font-size: 16px;
        line-height: 1.8;
    }
    .entity-card {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 10px;
        margin: 10px 0;
        border-left: 4px solid #4CAF50;
    }
    .metric-card {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state variables."""
    if 'processor' not in st.session_state:
        st.session_state.processor = ArabicNERProcessor()
    if 'extraction_history' not in st.session_state:
        st.session_state.extraction_history = []

def display_extraction_results(extracted_data, original_text):
    """Display the extraction results in a formatted way."""
    
    # Create columns for layout
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")
        
        # Contract type
        if extracted_data['contract_type']:
            st.success(f"**Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯:** {extracted_data['contract_type']}")
        
        # Names section
        if extracted_data['names']:
            st.markdown("### ğŸ‘¤ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©")
            for i, name in enumerate(extracted_data['names'], 1):
                st.markdown(f"**{i}.** {name}")
        
        # Dates section
        if extracted_data['dates']:
            st.markdown("### ğŸ“… Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®")
            for i, date in enumerate(extracted_data['dates'], 1):
                st.markdown(f"**{i}.** {date}")
        
        # Duration section
        if extracted_data['durations']:
            st.markdown("### â±ï¸ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©")
            for i, duration in enumerate(extracted_data['durations'], 1):
                st.markdown(f"**{i}.** {duration}")
        
        # Amounts section
        if extracted_data['amounts']:
            st.markdown("### ğŸ’° Ø§Ù„Ù…Ø¨Ø§Ù„Øº Ø§Ù„Ù…Ø§Ù„ÙŠØ©")
            for i, amount in enumerate(extracted_data['amounts'], 1):
                st.markdown(f"**{i}.** {amount}")
        
        # Locations section
        if extracted_data['locations']:
            st.markdown("### ğŸ“ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹")
            for i, location in enumerate(extracted_data['locations'], 1):
                st.markdown(f"**{i}.** {location}")
        
        # Phone numbers section
        if extracted_data['phone_numbers']:
            st.markdown("### ğŸ“ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡Ø§ØªÙ")
            for i, phone in enumerate(extracted_data['phone_numbers'], 1):
                st.markdown(f"**{i}.** {phone}")
    
    with col2:
        st.subheader("ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªÙ†Ø¯")
        
        # Document statistics
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", extracted_data['word_count'])
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù", extracted_data['text_length'])
        st.metric("Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©", extracted_data['language'])
        
        # Entity counts
        st.markdown("### Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©")
        entities_count = {
            'Ø§Ù„Ø£Ø³Ù…Ø§Ø¡': len(extracted_data['names']),
            'Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®': len(extracted_data['dates']),
            'Ø§Ù„Ù…Ø¯Ø¯': len(extracted_data['durations']),
            'Ø§Ù„Ù…Ø¨Ø§Ù„Øº': len(extracted_data['amounts']),
            'Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹': len(extracted_data['locations']),
            'Ø§Ù„Ù‡ÙˆØ§ØªÙ': len(extracted_data['phone_numbers'])
        }
        
        for entity_type, count in entities_count.items():
            if count > 0:
                st.metric(entity_type, count)

def export_results_to_json(extracted_data, original_text):
    """Export results to JSON format."""
    export_data = {
        'timestamp': datetime.now().isoformat(),
        'original_text_preview': original_text[:200] + "..." if len(original_text) > 200 else original_text,
        'extraction_results': extracted_data,
        'summary': st.session_state.processor.format_extraction_summary(extracted_data)
    }
    return json.dumps(export_data, ensure_ascii=False, indent=2)

def main():
    """Main application function."""
    initialize_session_state()
    
    # Header
    st.title("ğŸ“„ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    st.markdown("**Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©**")
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        
        # File upload option
        uploaded_file = st.file_uploader(
            "Ø±ÙØ¹ Ù…Ù„Ù Ù†ØµÙŠ",
            type=['txt', 'docx', 'pdf'],
            help="ÙŠØ¯Ø¹Ù… Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ø­Ø§Ù„ÙŠØ§Ù‹"
        )
        
        # Processing options
        st.subheader("Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
        show_confidence = st.checkbox("Ø¥Ø¸Ù‡Ø§Ø± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", value=False)
        detailed_view = st.checkbox("Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ", value=True)
        
        # History section
        if st.session_state.extraction_history:
            st.subheader("ğŸ“š Ø§Ù„Ø³Ø¬Ù„")
            for i, item in enumerate(reversed(st.session_state.extraction_history[-5:]), 1):
                with st.expander(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ {i} - {item['timestamp'][:10]}"):
                    st.text(item['text_preview'])
                    if st.button(f"Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ", key=f"history_{i}"):
                        st.session_state.current_text = item['original_text']
                        st.experimental_rerun()
    
    # Main content area
    tabs = st.tabs(["ğŸ“ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ", "ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "ğŸ“‹ Ø§Ù„ØªÙ‚Ø±ÙŠØ±"])
    
    with tabs[0]:
        st.subheader("Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
        
        # Text input methods
        input_method = st.radio(
            "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„:",
            ["ÙƒØªØ§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©", "Ø±ÙØ¹ Ù…Ù„Ù"],
            horizontal=True
        )
        
        text_input = ""
        
        if input_method == "ÙƒØªØ§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©":
            text_input = st.text_area(
                "Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ:",
                height=300,
                placeholder="Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ù†Ø§...",
                help="ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø® ÙˆÙ„ØµÙ‚ Ø§Ù„Ø¹Ù‚Ø¯ Ø£Ùˆ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ù‡Ù†Ø§"
            )
        
        elif input_method == "Ø±ÙØ¹ Ù…Ù„Ù" and uploaded_file:
            try:
                # Handle different file types
                if uploaded_file.type == "text/plain":
                    text_input = str(uploaded_file.read(), "utf-8")
                else:
                    st.warning("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„Ù Ù†ØµÙŠ (.txt)")
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        
        # Sample texts for testing
        with st.expander("ğŸ§ª Ù†ØµÙˆØµ ØªØ¬Ø±ÙŠØ¨ÙŠØ©"):
            sample_contract = """
            Ø¹Ù‚Ø¯ Ø¹Ù…Ù„
            
            Ø¨ÙŠÙ† Ø§Ù„Ø³ÙŠØ¯ Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯ Ø¹Ù„ÙŠ (Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø£ÙˆÙ„) ÙˆØ§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù„Ù„ØªØ·ÙˆÙŠØ± (Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø«Ø§Ù†ÙŠ)
            
            Ø¨ØªØ§Ø±ÙŠØ® 15/03/2024ØŒ ØªÙ… Ø§Ù„Ø§ØªÙØ§Ù‚ Ø¹Ù„Ù‰ Ø¹Ù‚Ø¯ Ø¹Ù…Ù„ Ù„Ù…Ø¯Ø© Ø³Ù†ØªÙŠÙ† Ø¨Ø±Ø§ØªØ¨ Ø´Ù‡Ø±ÙŠ Ù‚Ø¯Ø±Ù‡ 8000 Ø±ÙŠØ§Ù„ Ø³Ø¹ÙˆØ¯ÙŠ.
            
            Ù…ÙƒØ§Ù† Ø§Ù„Ø¹Ù…Ù„: Ø§Ù„Ø±ÙŠØ§Ø¶ØŒ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
            Ù‡Ø§ØªÙ: +966501234567
            
            ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ 1/04/2024 ÙˆÙŠÙ†ØªÙ‡ÙŠ ÙÙŠ 31/03/2026.
            """
            
            if st.button("Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ"):
                text_input = sample_contract
                st.experimental_rerun()
        
        # Process button
        if st.button("ğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ", type="primary", disabled=not text_input.strip()):
            if text_input.strip():
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ..."):
                    try:
                        # Process the document
                        extracted_data = st.session_state.processor.process_document(text_input)
                        
                        # Store in session state
                        st.session_state.current_extraction = extracted_data
                        st.session_state.current_text = text_input
                        
                        # Add to history
                        history_item = {
                            'timestamp': datetime.now().isoformat(),
                            'text_preview': text_input[:100] + "...",
                            'original_text': text_input,
                            'extraction_data': extracted_data
                        }
                        st.session_state.extraction_history.append(history_item)
                        
                        st.success("ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
                        st.balloons()
                        
                    except Exception as e:
                        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
    
    with tabs[1]:
        if 'current_extraction' in st.session_state:
            display_extraction_results(
                st.session_state.current_extraction,
                st.session_state.current_text
            )
            
            # Export options
            st.subheader("ğŸ“¥ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ’¾ ØªØµØ¯ÙŠØ± JSON"):
                    json_data = export_results_to_json(
                        st.session_state.current_extraction,
                        st.session_state.current_text
                    )
                    st.download_button(
                        label="ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù JSON",
                        data=json_data,
                        file_name=f"extraction_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
            
            with col2:
                if st.button("ğŸ“Š ØªØµØ¯ÙŠØ± CSV"):
                    # Create a simple CSV with extracted entities
                    df_data = []
                    for entity_type, entities in {
                        'Names': st.session_state.current_extraction['names'],
                        'Dates': st.session_state.current_extraction['dates'],
                        'Durations': st.session_state.current_extraction['durations'],
                        'Amounts': st.session_state.current_extraction['amounts'],
                        'Locations': st.session_state.current_extraction['locations'],
                        'Phone Numbers': st.session_state.current_extraction['phone_numbers']
                    }.items():
                        for entity in entities:
                            df_data.append({'Entity Type': entity_type, 'Value': entity})
                    
                    if df_data:
                        df = pd.DataFrame(df_data)
                        csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù CSV",
                            data=csv_data,
                            file_name=f"extraction_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
        else:
            st.info("ğŸ‘ˆ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† ØªØ¨ÙˆÙŠØ¨ 'Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ'")
    
    with tabs[2]:
        if 'current_extraction' in st.session_state:
            st.subheader("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")
            
            # Generate summary
            summary = st.session_state.processor.format_extraction_summary(
                st.session_state.current_extraction
            )
            
            st.markdown("### Ø§Ù„Ù…Ù„Ø®Øµ")
            st.markdown(f'<div class="arabic-text">{summary}</div>', unsafe_allow_html=True)
            
            # Detailed breakdown
            st.markdown("### Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
            with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…"):
                st.json(st.session_state.current_extraction)
        else:
            st.info("ğŸ‘ˆ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† ØªØ¨ÙˆÙŠØ¨ 'Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ'")
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
        ØªÙ… ØªØ·ÙˆÙŠØ± Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        </div>
        """, 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()